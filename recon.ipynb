{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38b3935a-98bb-47ae-a17a-95d2be035351",
   "metadata": {},
   "source": [
    "# Using MNIST model on our images and drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c396f-8dea-4e8e-bf64-86138ce76525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2578a206-c504-417f-a4ae-87bbe32cd584",
   "metadata": {},
   "source": [
    "## Renaming loaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9610887-2dd7-4717-b7a3-1a68b3f19f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(folder_path, template):\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    files = [file for file in files if os.path.isfile(os.path.join(folder_path, file))]\n",
    "\n",
    "    files.sort()\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        _, ext = os.path.splitext(file)\n",
    "        new_name = f\"{template}{i+1:04d}{ext}\"\n",
    "        os.rename(os.path.join(folder_path, file), os.path.join(folder_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704642fb-25ba-4b37-9b97-43fb390e2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_path = 'data/webcam'\n",
    "drawing_path = 'data/drawings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760c2bff-4877-49fc-a6ec-9cfff13a5482",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_files(webcam_path, 'img_')\n",
    "rename_files(drawing_path, 'img_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff94011e-06c6-4c1b-8e39-35042f6e4653",
   "metadata": {},
   "outputs": [],
   "source": [
    "webcam_pics = os.listdir(webcam_path)\n",
    "drawing_pics = os.listdir(drawing_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f0473-5360-478d-b99d-28eb6d696dbb",
   "metadata": {},
   "source": [
    "## Processing webcam images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f8d84-c699-4509-b385-b0d6c2ff6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_webcam_image(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    _, img_thresh = cv2.threshold(img, 135, 255, cv2.THRESH_BINARY)\n",
    "    img_norm = img_thresh / 255.0\n",
    "\n",
    "    return img_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bcef08-87a6-4460-890e-ff7f2b8953f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess webcam images\n",
    "processed_webcam_images = []\n",
    "for file in webcam_pics:\n",
    "    image_path = os.path.join(webcam_path, file)\n",
    "    processed_image = preprocess_webcam_image(image_path)\n",
    "    processed_webcam_images.append(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c71ffe5-e199-4b68-997e-ecc115ed2878",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "num_images_to_display = 5  # Change this to the number of images you want to display\n",
    "for i in range(num_images_to_display):\n",
    "    plt.subplot(1, num_images_to_display, i + 1)\n",
    "    plt.imshow(processed_webcam_images[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7abb17-f136-4482-9b82-8004b6ce1c80",
   "metadata": {},
   "source": [
    "## Processing drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f728f7be-c19e-496c-8eef-c689c8be949f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_drawing_image(path):\n",
    "    valid_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    if not any(path.lower().endswith(ext) for ext in valid_extensions):\n",
    "        print(f\"Skipping non-image file: {path}\")\n",
    "        return None\n",
    "    \n",
    "    # Attempt to read the image\n",
    "    img = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "    # Check if the image has an alpha channel\n",
    "    if img.shape[2] == 4:\n",
    "        alpha_channel = img[:, :, 3]\n",
    "        \n",
    "        # Replace transparent pixels with white\n",
    "        img[alpha_channel == 0] = [255, 255, 255, 255]\n",
    "        \n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    img_resized = cv2.resize(img_gray, (28, 28))\n",
    "    \n",
    "    _, img_thresh = cv2.threshold(img_resized, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    img_normalized = img_thresh / 255.0\n",
    "\n",
    "    img_inverted = abs(1 - img_normalized)\n",
    "\n",
    "    return img_inverted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff0bc77-8bbe-42b0-8ea6-82ad55e8ba9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess drawing images\n",
    "processed_drawing_images = []\n",
    "for file in drawing_pics:\n",
    "    image_path = os.path.join(drawing_path, file)\n",
    "    processed_image = preprocess_drawing_image(image_path)\n",
    "    processed_drawing_images.append(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f47e999-5299-4043-b2aa-0a7153c4f562",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "num_images_to_display = len(processed_drawing_images)\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    plt.subplot(1, num_images_to_display, i + 1)\n",
    "    plt.imshow(processed_drawing_images[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac7d5d-bb09-4352-8869-8787f8f2c47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_labels = [\"6\", \"1\", \"8\", \"9\", \"3\", \"3\", \"5\", \"3\", \"6\", \"4\", \"4\", \"7\", \"3\", \"2\", \"9\", \"4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65798a2a-7bad-46ae-a9d8-109a828abd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "num_images_to_display = len(processed_drawing_images)\n",
    "\n",
    "# Define labels for the drawings\n",
    "drawing_labels = [\"Label1\", \"Label2\", \"Label3\", ...]  # Replace with your actual labels\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    plt.subplot(1, num_images_to_display, i + 1)\n",
    "    plt.imshow(processed_drawing_images[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(f\"Prediction: {drawing_predictions[i]}\\nLabel: {drawing_labels[i]}\", fontsize=12)  # Include the prediction and label in the title\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b86a67-c0d5-4f3d-a075-9baf1cf6420a",
   "metadata": {},
   "source": [
    "## Testing my MNIST model on my drawings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5249d522-6742-4cad-aeeb-99e44b1e57f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'mnist_simple.keras'\n",
    "\n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651663f4-9afb-47ff-9c10-281de2449f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawing_predictions = []\n",
    "\n",
    "for drawing_image in processed_drawing_images:\n",
    "    # Flatten and normalize the drawing image\n",
    "    drawing_image = drawing_image.reshape(1, 28*28)\n",
    "\n",
    "    # Make predictions on the drawing image\n",
    "    predictions = model.predict(drawing_image)\n",
    "\n",
    "    # Interpret the predictions\n",
    "    predicted_class = np.argmax(predictions)\n",
    "    drawing_predictions.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c5565-04b6-4109-bfbc-bf2d2a6095a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "num_images_to_display = len(processed_drawing_images)\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    plt.subplot(1, num_images_to_display, i + 1)\n",
    "    plt.imshow(processed_drawing_images[i], cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "    # Include the prediction and actual label in the title\n",
    "    plt.title(f\"Pred: {drawing_predictions[i]}\\nReal: {drawing_labels[i]}\", fontsize=12)\n",
    "    \n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
